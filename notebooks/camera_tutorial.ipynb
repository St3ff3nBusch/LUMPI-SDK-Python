{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUMPI Camera Tutorial\n",
    "This Jupyter notebook explains the camera example in more detail. This tutorial uses:\n",
    "- the LUMPI parser \n",
    "  - to load the labels and point clouds\n",
    "  - to interpolate the bounding boxes for the camera frames\n",
    "  - the CameraView within the LUMPParser is used\n",
    "    - to load the camera images, masks, and parameters\n",
    "    - to project the 3D bounding boxes from the lidar frame into the camera frame\n",
    "    - to use the frustum for bounding box clipping\n",
    "\n",
    "First, the path to the SDK objects is appended and all necessary functions are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from objects.LUMPIParser import LUMPIParser\n",
    "from objects.PointCloudFilter import PointCloudFilter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the path to the LUMP dataset is defined. The following structure is expected to load all meta information, camera devices, and point cloud files by the **measurement_id**:\n",
    "- Root\n",
    "  - Measurement**1**\n",
    "    - lidar\n",
    "        - 0000000.ply\n",
    "    - cam\n",
    "        - **5** (camera device id)\n",
    "            - video.mp4\n",
    "            - mask.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lp = LUMPIParser(path=\"/media/busch/ExternSSD1T/LUMPI\")\n",
    "# Initialize Measurement\n",
    "measurement_id = 5\n",
    "lp.read_point_cloud_file_list(measurement_id)\n",
    "lp.read_all_cameras(measurement_id, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, all labels are loaded for the measurements by an arbitrary path. This line expects the labels as a SGT.csv file within each measurement directory:\n",
    "- Root\n",
    "  - Measurement**1**\n",
    "    - lidar\n",
    "    - SGT.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lp.read_track(os.path.join(lp.path, \"Experiment\" + str(measurement_id), \"SGT.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the background meta is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "filter = PointCloudFilter()\n",
    "filter.read_background(os.path.join(lp.path, \"Experiment\" + str(measurement_id), \"background\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, a camera is chosen and a start time is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Choose camera\n",
    "cam = lp.cameras[0]\n",
    "time = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line initializes matplotlib for displaying the image directly in the Jupyter notebook and is not part of the camera_example.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialization of notebook display\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line initializes the plot within the notebook. The loop iterates over all frames of the camera:\n",
    "- increment the time by FPS\n",
    "- get the index of point clouds (sometimes a frame is between two point clouds)\n",
    "- load frame from camera (optional with mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i in range(100):\n",
    "    time += 1. / cam.fps\n",
    "    next_time = time + 1 / cam.fps\n",
    "    index = int(np.floor(time * 10))\n",
    "    next_index = int(np.floor(next_time * 10))\n",
    "    if not lp.read_point_cloud(index):\n",
    "        continue\n",
    "    cam.set_frame(int(np.floor(time * cam.fps)), True)\n",
    "    # Filter point cloud by frame time and foreground\n",
    "    fb = filter.filter_background(lp.get_points_meta())\n",
    "    id2 = filter.filter_points_by_time(lp.pc, time, next_time)\n",
    "    id3 = np.intersect1d(fb[0], id2)\n",
    "    cam.plot_point_cloud(lp.get_xyz()[id3, :], [1, 0, 0])\n",
    "    # Read also next point cloud if frame interval reaches the next cloud\n",
    "    if next_index - index > 0:\n",
    "        if not lp.read_point_cloud(next_index):\n",
    "            continue\n",
    "        # Filter point cloud by frame time and foreground\n",
    "        fb = filter.filter_background(lp.get_points_meta())\n",
    "        id2 = filter.filter_points_by_time(lp.pc, time, next_time)\n",
    "        id3 = np.intersect1d(fb[0], id2)\n",
    "        cam.plot_point_cloud(lp.get_xyz()[id3, :], [1, 0, 0])\n",
    "    # Interpolate bounding boxes to camera frame\n",
    "    bb = lp.get_bounding_boxes_at(time)\n",
    "    cam.plot_bounding_boxes_3D(bb, [255, 0, 0])\n",
    "  \n",
    "    # Show image in notebook\n",
    "    ax.clear()\n",
    "    ax.imshow(cv2.cvtColor(cam.img, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')  # Hide axes\n",
    "    display(fig)\n",
    "    clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
